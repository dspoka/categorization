{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.layers import Merge, merge\n",
    "from keras.layers import Input\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "from collections import Counter\n",
    "from itertools import izip\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "import keras.callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "filename_model = '_bilingual_keras_output/english_json.txt'\n",
    "weights = '_bilingual_keras_output/english_weights.h5'\n",
    "\n",
    "with open(filename_model) as data_file1:    \n",
    "    data1 = json.load(data_file1)\n",
    "\n",
    "mono_model = model_from_json(json.dumps(data1))\n",
    "mono_model.load_weights(weights)\n",
    "\n",
    "filename_model = '_bilingual_keras_output/bilingual_json.txt'\n",
    "weights = '_bilingual_keras_output/bilingual_weights.h5'\n",
    "\n",
    "with open(filename_model) as data_file1:    \n",
    "    data1 = json.load(data_file1)\n",
    "\n",
    "bi_model = model_from_json(json.dumps(data1))\n",
    "bi_model.load_weights(weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[[  1.76175429e-04   4.00024564e-05]\n",
      " [  9.89112397e-05   2.18878074e-04]\n",
      " [  1.85459526e-04  -9.40225942e-05]\n",
      " [  9.54369309e-05  -1.39264259e-05]]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"268pt\" viewBox=\"0.00 0.00 140.00 268.00\" width=\"140pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 264)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-264 136,-264 136,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4597397840 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4597397840</title>\n",
       "<polygon fill=\"none\" points=\"-0.898438,-223 -0.898438,-259 132.898,-259 132.898,-223 -0.898438,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-236.8\">input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4598073616 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4598073616</title>\n",
       "<polygon fill=\"none\" points=\"11.1567,-149 11.1567,-185 120.843,-185 120.843,-149 11.1567,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-162.8\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4597397840&#45;&gt;4598073616 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4597397840-&gt;4598073616</title>\n",
       "<path d=\"M66,-222.937C66,-214.807 66,-204.876 66,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.5001,-195.441 66,-185.441 62.5001,-195.441 69.5001,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4598073744 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4598073744</title>\n",
       "<polygon fill=\"none\" points=\"11.1567,-75 11.1567,-111 120.843,-111 120.843,-75 11.1567,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-88.8\">dense_2 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4598073616&#45;&gt;4598073744 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4598073616-&gt;4598073744</title>\n",
       "<path d=\"M66,-148.937C66,-140.807 66,-130.876 66,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.5001,-121.441 66,-111.441 62.5001,-121.441 69.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4598854800 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4598854800</title>\n",
       "<polygon fill=\"none\" points=\"11.1567,-1 11.1567,-37 120.843,-37 120.843,-1 11.1567,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-14.8\">dense_3 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4598073744&#45;&gt;4598854800 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4598073744-&gt;4598854800</title>\n",
       "<path d=\"M66,-74.937C66,-66.8072 66,-56.8761 66,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"69.5001,-47.4406 66,-37.4407 62.5001,-47.4407 69.5001,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print mono_model.layers[3].get_weights()[0].shape\n",
    "\n",
    "X = mono_model.layers[3].get_weights()[0]\n",
    "tsne_model = TSNE(n_components=2, random_state=0)\n",
    "print tsne_model.fit_transform(X) \n",
    "\n",
    "SVG(model_to_dot(mono_model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2.14581728, -0.07849294, -0.28278583],\n",
      "       [-0.14867061,  0.9816798 ,  0.02883432],\n",
      "       [ 0.        ,  0.        ,  1.        ]], dtype=float32), array([-0.39793718,  0.00276767,  1.12602556], dtype=float32), array([[-0.01442386,  1.36969423, -1.19641745, -0.03035698],\n",
      "       [-0.01896751,  0.03565705,  0.22808591,  0.02278585],\n",
      "       [ 0.02280026, -0.00605218,  0.68584555, -0.02442775]], dtype=float32), array([ -2.53282748e-02,   2.82219239e-02,   6.15046322e-01,\n",
      "        -1.34999518e-05], dtype=float32), array([[-0.03652897, -0.02381084,  0.00150968,  0.01455416],\n",
      "       [-0.77774566,  1.03023469, -0.17602335, -0.11251332],\n",
      "       [ 1.07095408, -0.96958053, -0.10761246, -0.12237456],\n",
      "       [ 0.01377018,  0.03996072, -0.03478393, -0.02784591]], dtype=float32), array([ 1.15648448,  1.23269427, -1.19012511, -1.19905651], dtype=float32)]\n",
      "\n",
      "[array([[ 1.7082516 , -0.42735323, -0.25432134],\n",
      "       [ 0.26024786,  1.93305051,  0.13075809],\n",
      "       [ 0.        ,  0.        ,  1.        ]], dtype=float32), array([-0.49074012, -0.27315956,  0.99413127], dtype=float32), array([[-0.02144611,  0.79203749, -1.06051004, -0.0299608 ],\n",
      "       [-0.02819774, -0.1689378 , -0.3145172 ,  0.02378591],\n",
      "       [ 0.03956049, -0.33603463,  0.30952626, -0.02415891]], dtype=float32), array([ -8.10937770e-03,  -3.92074525e-01,   2.68259913e-01,\n",
      "         6.21638901e-05], dtype=float32), array([[-0.02442072, -0.02275355,  0.02148266, -0.10908242],\n",
      "       [-0.02100133, -0.03523806, -0.08731488,  1.67827356],\n",
      "       [-0.0344619 ,  0.01963064,  0.07139537,  0.14307313]], dtype=float32), array([ 0.        ,  0.01810157,  0.05515012,  0.03989351], dtype=float32), array([[-0.04390666, -0.02337723,  0.02778185, -0.00477395],\n",
      "       [-0.6272772 ,  0.49095973,  0.27765197, -0.17738238],\n",
      "       [ 0.27074027, -0.75029224,  0.65818447, -0.30724573],\n",
      "       [ 0.01329053,  0.04029598, -0.03496379, -0.02752166]], dtype=float32), array([-0.11820163, -0.05567192,  0.11803006,  0.05584147], dtype=float32), array([[  2.44542658e-02,   4.76165302e-02,  -2.61124056e-02,\n",
      "         -2.04277150e-02],\n",
      "       [  2.87994575e-02,   3.01230401e-02,  -6.73207222e-03,\n",
      "         -5.56757711e-02],\n",
      "       [  1.73653867e-02,  -8.13129125e-04,   7.42158368e-02,\n",
      "         -1.00604184e-01],\n",
      "       [ -3.63123953e-01,  -4.17661875e-01,  -6.35717809e-01,\n",
      "          1.43250918e+00]], dtype=float32), array([-1.04833674, -1.00443614,  1.14807141,  0.90470147], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"342pt\" viewBox=\"0.00 0.00 244.00 342.00\" width=\"244pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-338 240,-338 240,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4598358608 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4598358608</title>\n",
       "<polygon fill=\"none\" points=\"51.1016,-297 51.1016,-333 184.898,-333 184.898,-297 51.1016,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-310.8\">input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 4605361232 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4605361232</title>\n",
       "<polygon fill=\"none\" points=\"63.1567,-223 63.1567,-259 172.843,-259 172.843,-223 63.1567,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-236.8\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4598358608&#45;&gt;4605361232 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4598358608-&gt;4605361232</title>\n",
       "<path d=\"M118,-296.937C118,-288.807 118,-278.876 118,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"121.5,-269.441 118,-259.441 114.5,-269.441 121.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605360976 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4605360976</title>\n",
       "<polygon fill=\"none\" points=\"-0.843262,-149 -0.843262,-185 108.843,-185 108.843,-149 -0.843262,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"54\" y=\"-162.8\">dense_2 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4605361232&#45;&gt;4605360976 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4605361232-&gt;4605360976</title>\n",
       "<path d=\"M102.833,-222.937C94.8995,-214.012 85.0363,-202.916 76.2554,-193.037\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"78.7624,-190.59 69.5028,-185.441 73.5306,-195.24 78.7624,-190.59\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605498704 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4605498704</title>\n",
       "<polygon fill=\"none\" points=\"127.157,-149 127.157,-185 236.843,-185 236.843,-149 127.157,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182\" y=\"-162.8\">dense_4 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4605361232&#45;&gt;4605498704 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4605361232-&gt;4605498704</title>\n",
       "<path d=\"M133.167,-222.937C141.101,-214.012 150.964,-202.916 159.745,-193.037\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"162.469,-195.24 166.497,-185.441 157.238,-190.59 162.469,-195.24\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605548496 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4605548496</title>\n",
       "<polygon fill=\"none\" points=\"-0.843262,-75 -0.843262,-111 108.843,-111 108.843,-75 -0.843262,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"54\" y=\"-88.8\">dense_3 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4605360976&#45;&gt;4605548496 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4605360976-&gt;4605548496</title>\n",
       "<path d=\"M54,-148.937C54,-140.807 54,-130.876 54,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"57.5001,-121.441 54,-111.441 50.5001,-121.441 57.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605599888 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4605599888</title>\n",
       "<polygon fill=\"none\" points=\"127.157,-75 127.157,-111 236.843,-111 236.843,-75 127.157,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182\" y=\"-88.8\">dense_5 (Dense)</text>\n",
       "</g>\n",
       "<!-- 4605498704&#45;&gt;4605599888 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4605498704-&gt;4605599888</title>\n",
       "<path d=\"M182,-148.937C182,-140.807 182,-130.876 182,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"185.5,-121.441 182,-111.441 178.5,-121.441 185.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605602256 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4605602256</title>\n",
       "<polygon fill=\"none\" points=\"61.0752,-1 61.0752,-37 174.925,-37 174.925,-1 61.0752,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-14.8\">merge_1 (Merge)</text>\n",
       "</g>\n",
       "<!-- 4605548496&#45;&gt;4605602256 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4605548496-&gt;4605602256</title>\n",
       "<path d=\"M69.1671,-74.937C77.1005,-66.0119 86.9637,-54.9159 95.7446,-45.0373\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"98.4694,-47.2401 102.497,-37.4407 93.2376,-42.5895 98.4694,-47.2401\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4605599888&#45;&gt;4605602256 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4605599888-&gt;4605602256</title>\n",
       "<path d=\"M166.833,-74.937C158.899,-66.0119 149.036,-54.9159 140.255,-45.0373\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"142.762,-42.5895 133.503,-37.4407 137.531,-47.2401 142.762,-42.5895\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print mono_model.get_weights()\n",
    "print\n",
    "print bi_model.get_weights()\n",
    "\n",
    "SVG(model_to_dot(bi_model).create(prog='dot', format='svg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_pca_weights(pca_filepath):\n",
    "    '''expects a file with weight on a each new line '''\n",
    "    pca_results = open(data_directory+pca_filepath,'r')\n",
    "    pca_weights = np.zeros((PCA_dimension+1,PCA_dimension+1))\n",
    "    i = 0\n",
    "    for line in pca_results:\n",
    "        a = float(line.strip())\n",
    "        pca_weights[i][i] = a\n",
    "        i +=1\n",
    "    pca_weights[i][i] = 1.0\n",
    "    # unsure what to set the language gate to start at\n",
    "    # currently set to 1\n",
    "    bias = np.concatenate((np.zeros(PCA_dimension),np.ones(1)))\n",
    "    pca_results.close()\n",
    "    return [pca_weights,bias]\n",
    "\n",
    "def load_language_data(language):\n",
    "  ''' 1. seperate train and test better\n",
    "      2. change number of iterations for test/train\n",
    "      dut_x = situation#, 56 floats \\n\n",
    "      dut_y = preposition number \\n\n",
    "  '''\n",
    "  f = open(data_directory+language+'_x','r')\n",
    "  g = open(data_directory+language+'_y','r')\n",
    "  h = open(data_directory+'golden_'+language,'r')\n",
    "  situation_x_data = {}\n",
    "  x_train = []\n",
    "  y_train = []\n",
    "  x_validation = []\n",
    "  y_validation =[]\n",
    "  x_test = []\n",
    "  y_test = []\n",
    "  situation_train = []\n",
    "\n",
    "  for x_line,y_line in izip(f,g):\n",
    "    x_data = x_line.strip().split(',')\n",
    "    y_data = y_line.strip().split(',')\n",
    "    x_data.insert(PCA_dimension+1,0)\n",
    "\n",
    "    sit_num = int(x_data[0])\n",
    "    situation_train += [sit_num] # list of all training situations\n",
    "\n",
    "    situation_x_data[sit_num] = map(float,x_data[1:])\n",
    "    # print x_data\n",
    "    x_train += [x_data[1:]]\n",
    "    y = [0 for x in range(dut_num_preps + ger_num_preps)]\n",
    "    y[map(int,y_data)[0]] = 1\n",
    "    y_train += [y]\n",
    "\n",
    "  #first add language feature\n",
    "  sit_number_to_preps = make_sit_to_prep(language)\n",
    "  xy_test_data, test_situation = make_test_data(language,sit_number_to_preps, situation_x_data)\n",
    "  for xy in xy_test_data:\n",
    "    x_test += [xy[:-1]]\n",
    "    y = [0 for x in range(dut_num_preps + ger_num_preps)]\n",
    "    y[xy[-1:][0]] = 1\n",
    "    # y[] = 1\n",
    "    y_test += [y]\n",
    "\n",
    "  x_validation = x_test\n",
    "  y_validation = y_test\n",
    "\n",
    "  #add a bunch of asserts, about sizes, and types of things\n",
    "  # print len(test_situation[0])\n",
    "\n",
    "  # counting_situations(situation_train)\n",
    "\n",
    "  return x_train, y_train, x_validation, y_validation, x_test, y_test, test_situation\n",
    "\n",
    "def counting_situations(situations):\n",
    "  g = open(data_directory+language+'_y','r')\n",
    "  y_s = []\n",
    "  for y_line in g:\n",
    "    y_data = y_line.strip().split(',')\n",
    "    y_s += map(int,y_data)\n",
    "  preps = []\n",
    "  for y in y_s:\n",
    "    preps += [prep_num_to_prep(language,y)]\n",
    "  c = Counter(zip(situations,preps))\n",
    "  print sorted(c.items())\n",
    "\n",
    "def prep_num_to_prep(language, prep_num):\n",
    "  for key in term_indices[language].keys():\n",
    "    if(prep_num == term_indices[language][key]):\n",
    "      return key\n",
    "\n",
    "def make_test_data(language,situations_to_preps, situation_x_data):\n",
    "  ''' should this have to read through all lines '''\n",
    "  xy_test_data = []\n",
    "  test_situation  = []\n",
    "  for situation in situations_to_preps.keys():\n",
    "    xy = situation_x_data[situation]+[situations_to_preps[situation]]\n",
    "    xy_test_data += [xy]\n",
    "    test_situation += [situation]\n",
    "\n",
    "  return xy_test_data, test_situation\n",
    "\n",
    "def make_sit_to_prep(language):\n",
    "  test_data = set([]) # 56(PCA)+1(lang)|label\n",
    "  situations_to_preps = {} # map 71 situations to the correct preposition number\n",
    "  f = open(data_directory+'golden_'+language,'r')\n",
    "  for line in f:\n",
    "    line = line.strip().split(',')\n",
    "    #line = 63(sit#),over(prep),probability...\n",
    "    situations_to_preps[int(line[0])] = term_indices[language][line[1]]\n",
    "    #add asserts about length of data_structures\n",
    "  return situations_to_preps\n",
    "\n",
    "\n",
    "def lang_term_number(language, term):\n",
    "    print term, data[language][term]\n",
    "\n",
    "def load_term_indices():\n",
    "    f = open(data_directory+'term_indices')\n",
    "    data = json.load(f)\n",
    "    # for language in data:\n",
    "    #     print language\n",
    "    #     print data[language]\n",
    "\n",
    "def output_experiment(models):\n",
    "    ''' takes a list of models and\n",
    "    make a new directory with plots of models\n",
    "    weights of models, and summary of models'''\n",
    "    if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "    for model in models:\n",
    "        filepath_weights = directory+model.name + '_' + language +'_weights.txt'\n",
    "        model.save_weights(filepath_weights)\n",
    "\n",
    "        model.summary()# prints out summaries\n",
    "        filename = model.name + '_json.txt'\n",
    "        g = open(directory+'/'+filename,'w')\n",
    "        g.write(str(model.to_json()))\n",
    "        g.close()\n",
    "        plot(model, show_shapes=True, to_file=directory+'/'+model.name+'.png')\n",
    "\n",
    "def visualize_gates(model):\n",
    "    x_old = init_gate[0].diagonal()\n",
    "    x_final = model.get_weights()[0].diagonal()\n",
    "    x_index = [i for i in range(len(x_old)+1)]\n",
    "    y_index = [0,1,2,3]\n",
    "\n",
    "    intensity = np.concatenate(([x_old], [x_final], [np.subtract(x_final,x_old)]), axis=0)\n",
    "\n",
    "    print x_old\n",
    "    print x_final\n",
    "    print np.subtract(x_final, x_old)\n",
    "\n",
    "#     x, y = np.meshgrid(x_index, y_index)\n",
    "\n",
    "#     plt.pcolormesh(x, y, intensity)\n",
    "#     plt.colorbar() #need a colorbar to show the intensity scale\n",
    "#     plt.show() #boom\n",
    "    \n",
    "    \n",
    "\n",
    "mode = 'synthetic'\n",
    "language = 'dut'\n",
    "pca_filepath = 'results_PCA.csv'\n",
    "training_epoch = 200\n",
    "if (mode == 'real'):\n",
    "    time_stamp = time.strftime(\"%m-%d-%Y-%H-%M\")\n",
    "    data_directory = 'gen_data/'\n",
    "    german_filepath = 'NEED TO FILL IN'\n",
    "    dut_num_preps = 14\n",
    "    ger_num_preps = 10\n",
    "    PCA_dimension = 56\n",
    "    language_embedding_dimension = 28\n",
    "elif(mode =='fake'):\n",
    "    data_directory = 'fake_data/'\n",
    "    time_stamp = ''\n",
    "    dut_num_preps = 2\n",
    "    ger_num_preps = 3\n",
    "    PCA_dimension = 3\n",
    "    language_embedding_dimension = 4\n",
    "else:\n",
    "    data_directory = 'synthetic_data/'\n",
    "    time_stamp = ''\n",
    "    language = 'lang_1'\n",
    "    dut_num_preps = 2\n",
    "    ger_num_preps = 2\n",
    "    PCA_dimension = 2\n",
    "    language_embedding_dimension = 4\n",
    "\n",
    "directory = time_stamp+'_bilingual_keras_output/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "term_indices = json.load(open(data_directory+'term_indices'))\n",
    "X_train,y_train, X_validation, y_validation, X_test, y_test, test_situation = load_language_data(language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d0f2596c762f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_situation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "right_answer = [0 for x in range(71)]\n",
    "second_answer = [0 for x in range(71)]\n",
    "wrong_answer = [0 for x in range(71)]\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "for x,y,z in zip(model.predict(X_test, batch_size=1), y_test, test_situation):\n",
    "  print x, y,z\n",
    "  \n",
    "    \n",
    "  prediction = np.where(x==x.max())[0][0]\n",
    "  prediction_2 = np.argsort(x)[::-1][1]\n",
    "  correct_answer = np.where(y==y.max())[0][0]\n",
    "  if(prediction == correct_answer):\n",
    "    right_answer[z-1] += 1\n",
    "  elif(prediction_2 == correct_answer):\n",
    "    second_answer[z-1] += 1\n",
    "  else:\n",
    "    # print \" \" + str(prediction), correct_answer\n",
    "    wrong_answer[z-1] += 1\n",
    "  for key, value in term_indices[language].iteritems():\n",
    "    if value == prediction:\n",
    "      break\n",
    "    \n",
    "  print z,key #this prints out situation, preposition predicted\n",
    "\n",
    "\n",
    "print \"sums of right, 2nd, wrong\"\n",
    "print sum(right_answer)\n",
    "print sum(second_answer)\n",
    "print sum(wrong_answer)\n",
    "\n",
    "print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(second_answer)):\n",
    "  if(wrong_answer[i] + second_answer[i] == 1):\n",
    "    print i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 100 samples\n",
      "Epoch 1/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.8889Epoch 00000: val_acc improved from -inf to 1.00000, saving model to _bilingual_keras_output/lang_2_weights.00.hdf5\n",
      "100/100 [==============================] - 0s - loss: 0.1148 - acc: 0.8900 - val_loss: 0.0994 - val_acc: 1.0000\n",
      "Epoch 2/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9697Epoch 00001: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0979 - acc: 0.9700 - val_loss: 0.0907 - val_acc: 0.9900\n",
      "Epoch 3/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9798Epoch 00002: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0907 - acc: 0.9800 - val_loss: 0.0879 - val_acc: 0.9500\n",
      "Epoch 4/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9798Epoch 00003: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0860 - acc: 0.9800 - val_loss: 0.0827 - val_acc: 0.9900\n",
      "Epoch 5/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9798Epoch 00004: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0821 - acc: 0.9800 - val_loss: 0.0859 - val_acc: 0.9700\n",
      "Epoch 6/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9697Epoch 00005: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0821 - acc: 0.9700 - val_loss: 0.0783 - val_acc: 0.9900\n",
      "Epoch 7/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9899Epoch 00006: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0793 - acc: 0.9900 - val_loss: 0.0759 - val_acc: 0.9900\n",
      "Epoch 8/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9697Epoch 00007: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0795 - acc: 0.9700 - val_loss: 0.0746 - val_acc: 0.9900\n",
      "Epoch 9/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9899Epoch 00008: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0775 - acc: 0.9900 - val_loss: 0.0753 - val_acc: 0.9900\n",
      "Epoch 10/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9798Epoch 00009: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0756 - acc: 0.9800 - val_loss: 0.0731 - val_acc: 0.9900\n",
      "Epoch 11/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9697Epoch 00010: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0759 - acc: 0.9700 - val_loss: 0.0757 - val_acc: 0.9800\n",
      "Epoch 12/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9798Epoch 00011: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0760 - acc: 0.9800 - val_loss: 0.0758 - val_acc: 0.9700\n",
      "Epoch 13/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9899Epoch 00012: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0747 - acc: 0.9900 - val_loss: 0.0747 - val_acc: 0.9800\n",
      "Epoch 14/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 1.0000Epoch 00013: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0722 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9300\n",
      "Epoch 15/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9798Epoch 00014: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0736 - acc: 0.9800 - val_loss: 0.0726 - val_acc: 0.9800\n",
      "Epoch 16/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9798Epoch 00015: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0731 - acc: 0.9800 - val_loss: 0.0701 - val_acc: 0.9900\n",
      "Epoch 17/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9697Epoch 00016: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0732 - acc: 0.9700 - val_loss: 0.0723 - val_acc: 0.9800\n",
      "Epoch 18/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9798Epoch 00017: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0715 - acc: 0.9800 - val_loss: 0.0698 - val_acc: 0.9900\n",
      "Epoch 19/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9798Epoch 00018: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0731 - acc: 0.9800 - val_loss: 0.0706 - val_acc: 0.9900\n",
      "Epoch 20/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 1.0000Epoch 00019: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0695 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9700\n",
      "Epoch 21/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9798Epoch 00020: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0732 - acc: 0.9800 - val_loss: 0.0685 - val_acc: 0.9900\n",
      "Epoch 22/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9798Epoch 00021: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0718 - acc: 0.9800 - val_loss: 0.0697 - val_acc: 0.9900\n",
      "Epoch 23/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9899Epoch 00022: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0713 - acc: 0.9900 - val_loss: 0.0733 - val_acc: 0.9800\n",
      "Epoch 24/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9697Epoch 00023: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0738 - acc: 0.9700 - val_loss: 0.0679 - val_acc: 0.9900\n",
      "Epoch 25/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9798Epoch 00024: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0704 - acc: 0.9800 - val_loss: 0.0677 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9697Epoch 00025: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0709 - acc: 0.9700 - val_loss: 0.0794 - val_acc: 0.9700\n",
      "Epoch 27/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9899Epoch 00026: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0717 - acc: 0.9900 - val_loss: 0.0720 - val_acc: 0.9800\n",
      "Epoch 28/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9899Epoch 00027: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0699 - acc: 0.9900 - val_loss: 0.0710 - val_acc: 0.9800\n",
      "Epoch 29/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9899Epoch 00028: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0705 - acc: 0.9900 - val_loss: 0.0673 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9798Epoch 00029: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0710 - acc: 0.9800 - val_loss: 0.0692 - val_acc: 0.9900\n",
      "Epoch 31/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9596Epoch 00030: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0733 - acc: 0.9600 - val_loss: 0.0767 - val_acc: 0.9700\n",
      "Epoch 32/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9899Epoch 00031: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0697 - acc: 0.9900 - val_loss: 0.0680 - val_acc: 0.9900\n",
      "Epoch 33/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9899Epoch 00032: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0673 - acc: 0.9900 - val_loss: 0.0763 - val_acc: 0.9700\n",
      "Epoch 34/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9798Epoch 00033: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0726 - acc: 0.9800 - val_loss: 0.0671 - val_acc: 0.9900\n",
      "Epoch 35/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9798Epoch 00034: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0705 - acc: 0.9800 - val_loss: 0.0820 - val_acc: 0.9300\n",
      "Epoch 36/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9798Epoch 00035: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0690 - acc: 0.9800 - val_loss: 0.0718 - val_acc: 0.9800\n",
      "Epoch 37/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9899Epoch 00036: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0674 - acc: 0.9900 - val_loss: 0.0677 - val_acc: 0.9900\n",
      "Epoch 38/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9697Epoch 00037: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0706 - acc: 0.9700 - val_loss: 0.0669 - val_acc: 0.9900\n",
      "Epoch 39/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9697Epoch 00038: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0718 - acc: 0.9700 - val_loss: 0.0672 - val_acc: 0.9900\n",
      "Epoch 40/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9798Epoch 00039: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0690 - acc: 0.9800 - val_loss: 0.0696 - val_acc: 0.9800\n",
      "Epoch 41/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 1.0000Epoch 00040: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0666 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 0.9600\n",
      "Epoch 42/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9798Epoch 00041: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0696 - acc: 0.9800 - val_loss: 0.0685 - val_acc: 0.9900\n",
      "Epoch 43/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 1.0000Epoch 00042: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0679 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 0.9900\n",
      "Epoch 44/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9697Epoch 00043: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0705 - acc: 0.9700 - val_loss: 0.0671 - val_acc: 0.9900\n",
      "Epoch 45/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9798Epoch 00044: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0702 - acc: 0.9800 - val_loss: 0.0661 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9798Epoch 00045: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0716 - acc: 0.9800 - val_loss: 0.0664 - val_acc: 0.9900\n",
      "Epoch 47/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 1.0000Epoch 00046: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0662 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9900\n",
      "Epoch 48/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 1.0000Epoch 00047: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0665 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9900\n",
      "Epoch 49/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9899Epoch 00048: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0685 - acc: 0.9900 - val_loss: 0.0799 - val_acc: 0.9600\n",
      "Epoch 50/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9798Epoch 00049: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0716 - acc: 0.9800 - val_loss: 0.0712 - val_acc: 0.9800\n",
      "Epoch 51/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9697Epoch 00050: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0698 - acc: 0.9700 - val_loss: 0.0759 - val_acc: 0.9700\n",
      "Epoch 52/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9899Epoch 00051: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0707 - acc: 0.9900 - val_loss: 0.0660 - val_acc: 0.9900\n",
      "Epoch 53/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9798Epoch 00052: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0713 - acc: 0.9800 - val_loss: 0.0682 - val_acc: 0.9800\n",
      "Epoch 54/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9899Epoch 00053: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0695 - acc: 0.9900 - val_loss: 0.0658 - val_acc: 0.9900\n",
      "Epoch 55/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9899Epoch 00054: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0684 - acc: 0.9900 - val_loss: 0.0730 - val_acc: 0.9700\n",
      "Epoch 56/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 1.0000Epoch 00055: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0663 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9800\n",
      "Epoch 57/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9798Epoch 00056: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0694 - acc: 0.9800 - val_loss: 0.0682 - val_acc: 0.9900\n",
      "Epoch 58/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9798Epoch 00057: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0695 - acc: 0.9800 - val_loss: 0.0674 - val_acc: 0.9900\n",
      "Epoch 59/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9798Epoch 00058: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0711 - acc: 0.9800 - val_loss: 0.0839 - val_acc: 0.9300\n",
      "Epoch 60/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9798Epoch 00059: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0715 - acc: 0.9800 - val_loss: 0.0680 - val_acc: 0.9900\n",
      "Epoch 61/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9697Epoch 00060: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0713 - acc: 0.9700 - val_loss: 0.0656 - val_acc: 0.9900\n",
      "Epoch 62/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9798Epoch 00061: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0704 - acc: 0.9800 - val_loss: 0.0659 - val_acc: 0.9900\n",
      "Epoch 63/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9697Epoch 00062: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0707 - acc: 0.9700 - val_loss: 0.0678 - val_acc: 0.9900\n",
      "Epoch 64/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 1.0000Epoch 00063: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0660 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9900\n",
      "Epoch 65/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 1.0000Epoch 00064: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0655 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9900\n",
      "Epoch 66/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9697Epoch 00065: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0690 - acc: 0.9700 - val_loss: 0.0661 - val_acc: 0.9900\n",
      "Epoch 67/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 1.0000Epoch 00066: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0647 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9800\n",
      "Epoch 68/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9697Epoch 00067: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0708 - acc: 0.9700 - val_loss: 0.0654 - val_acc: 0.9900\n",
      "Epoch 69/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9899Epoch 00068: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0693 - acc: 0.9900 - val_loss: 0.0743 - val_acc: 0.9700\n",
      "Epoch 70/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9899Epoch 00069: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0701 - acc: 0.9900 - val_loss: 0.0693 - val_acc: 0.9800\n",
      "Epoch 71/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9798Epoch 00070: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0692 - acc: 0.9800 - val_loss: 0.0681 - val_acc: 0.9900\n",
      "Epoch 72/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9899Epoch 00071: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0688 - acc: 0.9900 - val_loss: 0.0692 - val_acc: 0.9800\n",
      "Epoch 73/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9899Epoch 00072: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0678 - acc: 0.9900 - val_loss: 0.0774 - val_acc: 0.9700\n",
      "Epoch 74/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9899Epoch 00073: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0669 - acc: 0.9900 - val_loss: 0.0652 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9697Epoch 00074: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0724 - acc: 0.9700 - val_loss: 0.0661 - val_acc: 0.9900\n",
      "Epoch 76/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9798Epoch 00075: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0695 - acc: 0.9700 - val_loss: 0.0676 - val_acc: 0.9900\n",
      "Epoch 77/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9798Epoch 00076: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0696 - acc: 0.9800 - val_loss: 0.0653 - val_acc: 0.9900\n",
      "Epoch 78/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9798Epoch 00077: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0698 - acc: 0.9800 - val_loss: 0.0662 - val_acc: 0.9900\n",
      "Epoch 79/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9798Epoch 00078: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0714 - acc: 0.9800 - val_loss: 0.0652 - val_acc: 0.9900\n",
      "Epoch 80/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9899Epoch 00079: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0675 - acc: 0.9900 - val_loss: 0.0652 - val_acc: 0.9900\n",
      "Epoch 81/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9697Epoch 00080: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0698 - acc: 0.9700 - val_loss: 0.0688 - val_acc: 0.9800\n",
      "Epoch 82/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9697Epoch 00081: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0721 - acc: 0.9700 - val_loss: 0.0663 - val_acc: 0.9900\n",
      "Epoch 83/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9899Epoch 00082: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0663 - acc: 0.9900 - val_loss: 0.0717 - val_acc: 0.9800\n",
      "Epoch 84/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9798Epoch 00083: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0687 - acc: 0.9800 - val_loss: 0.0657 - val_acc: 0.9900\n",
      "Epoch 85/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9697Epoch 00084: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0718 - acc: 0.9700 - val_loss: 0.0686 - val_acc: 0.9800\n",
      "Epoch 86/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9798Epoch 00085: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0687 - acc: 0.9800 - val_loss: 0.0668 - val_acc: 0.9900\n",
      "Epoch 87/200\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9899Epoch 00086: val_acc did not improve\n",
      "100/100 [==============================] - 0s - loss: 0.0675 - acc: 0.9900 - val_loss: 0.0656 - val_acc: 0.9900\n",
      "Epoch 88/200\n",
      " 46/100 [============>.................] - ETA: 0s - loss: 0.0628 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "language = 'lang_2'\n",
    "sgd = SGD(lr=0.1, decay=1e-6)\n",
    "checkpointer = ModelCheckpoint(filepath=directory+language+'_weights.{epoch:02d}.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "X_train,y_train, X_validation, y_validation, X_test, y_test, test_situation = load_language_data('lang_2')\n",
    "bi_model.compile(loss='mean_squared_error',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "bi_model.fit(X_train, y_train, batch_size=1, validation_data=(X_validation, y_validation),\n",
    "    nb_epoch=training_epoch, callbacks=[remote,checkpointer])\n",
    "\n",
    "# [ 1.  1.  1.]\n",
    "# [ 2.14581728  0.9816798   1.        ]\n",
    "# [ 1.14581728 -0.0183202   0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gate_weights = set_pca_weights(pca_filepath)\n",
    "init_gate = gate_weights\n",
    "visualize_gates(bi_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
